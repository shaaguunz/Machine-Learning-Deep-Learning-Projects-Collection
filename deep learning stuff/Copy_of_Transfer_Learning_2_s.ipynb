{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sbxMiz8GC0N5"
   },
   "source": [
    "# Implementing Transfer Learning\n",
    "\n",
    "* You will download a given dataset and then use transfer learning to build a classifier (to determine if an image contains cats or dogs).\n",
    "\n",
    "* You should use ResNet50\n",
    "\n",
    "* Evaluate your model on the testing accuracy\n",
    "\n",
    "* Fine-tune the feature extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "76kYjxJsktmv"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.datasets import cifar10\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v2ryXlfyEoTu"
   },
   "source": [
    "* Read about the image_dataset_from_directory() function: https://www.tensorflow.org/api_docs/python/tf/keras/utils/image_dataset_from_directory\n",
    "\n",
    "\n",
    "* You will use a dataset containing several thousand images of cats and dogs. Download and extract a zip file containing the images, then create a tf.data.Dataset for training and validation using the tf.keras.utils.image_dataset_from_directory utility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Lq34mJanEkmt",
    "outputId": "a85cc536-9e62-41e0-8b96-c459334b93f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip\n",
      "68608000/68606236 [==============================] - 0s 0us/step\n",
      "68616192/68606236 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Set the URL to the .zip file we will download\n",
    "_URL = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'\n",
    "\n",
    "# Download the file\n",
    "path_to_zip = tf.keras.utils.get_file('cats_and_dogs.zip', origin=_URL, extract=True)\n",
    "\n",
    "# Set the path\n",
    "PATH = os.path.join(os.path.dirname(path_to_zip), 'cats_and_dogs_filtered')\n",
    "train_dir = os.path.join(PATH, 'train')\n",
    "validation_dir = os.path.join(PATH, 'validation')\n",
    "\n",
    "# We will process the images in the directory in batches, here of size 12\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Resizing\n",
    "IMG_SIZE = (160, 160)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ph31RHe6J5jB"
   },
   "source": [
    "* The approach below avoidings loading all the data into memory by creating a tf.data.Dataset which will read the images in batches from the harddrive.\n",
    "\n",
    "* Read up about the arguement label_mode. There are different ways of doing this which will result in different loss functions and the number of units in the last layer (and activation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4xSqvkrPE82f",
    "outputId": "e05caa8d-2c60-4ecc-fe76-78c058691438"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_dataset = tf.keras.utils.image_dataset_from_directory(train_dir,\n",
    "                                                            shuffle=True,\n",
    "                                                            batch_size=BATCH_SIZE,\n",
    "                                                            image_size=IMG_SIZE,\n",
    "                                                            label_mode = \"categorical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2GaYugsiEko7",
    "outputId": "ce1bf446-0034-4eed-c1ee-598c1edfc5df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1000 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_dataset = tf.keras.utils.image_dataset_from_directory(validation_dir,\n",
    "                                                                 shuffle=True,\n",
    "                                                                 batch_size=BATCH_SIZE,\n",
    "                                                                 image_size=IMG_SIZE,\n",
    "                                                                 label_mode = \"categorical\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AdAf8r-WFi3b"
   },
   "source": [
    "## Some pre-processing needed\n",
    "\n",
    "* In a moment, you will download ResNet50 for use as your base model. \n",
    "\n",
    "* This model expects pixel values in [-1, 1], but at this point, the pixel values in your images are in [0, 255]. \n",
    "\n",
    "* To rescale them, use the preprocessing method included with the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zd7ApU0QEkrc"
   },
   "outputs": [],
   "source": [
    "preprocess_input = tf.keras.applications.resnet50.preprocess_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HmEgQ_BidLPP"
   },
   "source": [
    "## Import ResNet50\n",
    "\n",
    "* We need to make a modification to our approach. Since we need to pre-process the data, the way this is done is slightly different. First we define an Input, then call the ```preprocess_input()``` function, and then proceed as normal.\n",
    "\n",
    "```\n",
    "inputs = tf.keras.Input(shape=(160, 160, 3))\n",
    "x = preprocess_input(inputs)\n",
    "x = base_model(x)\n",
    "```\n",
    "\n",
    "* Note that there is a slight modification needed when you will define ```Model()``` but I am sure you can figure it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KdftfkmXDRqe"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WHvhL-t5DRs4"
   },
   "outputs": [],
   "source": [
    "base_model = ResNet50(weights='imagenet',\n",
    "                  include_top=False, \n",
    "                  input_shape=(160, 160, 3)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JENd_cBEgOSN"
   },
   "outputs": [],
   "source": [
    "# First we set the entire feature extractor to non-trainable\n",
    "base_model.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4NdUJ1hwfI4A"
   },
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(160, 160, 3))\n",
    "x = preprocess_input(inputs)\n",
    "x = base_model(x)\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "outputs = Dense(2, activation = \"softmax\")(x)\n",
    "model = tf.keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dHhC7hFth8ft",
    "outputId": "24477591-d204-4ccd-cab8-d81ff6b5a493"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_6 (InputLayer)        [(None, 160, 160, 3)]     0         \n",
      "                                                                 \n",
      " tf.__operators__.getitem_1   (None, 160, 160, 3)      0         \n",
      " (SlicingOpLambda)                                               \n",
      "                                                                 \n",
      " tf.nn.bias_add_1 (TFOpLambd  (None, 160, 160, 3)      0         \n",
      " a)                                                              \n",
      "                                                                 \n",
      " resnet50 (Functional)       (None, 5, 5, 2048)        23587712  \n",
      "                                                                 \n",
      " global_average_pooling2d_1   (None, 2048)             0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 4098      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23,591,810\n",
      "Trainable params: 23,538,690\n",
      "Non-trainable params: 53,120\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cLK7eYos_gdv"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "             optimizer='adam',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PGKxixm-zsSR",
    "outputId": "3079fac7-065e-46e7-a017-eddcbf643335"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "63/63 [==============================] - 30s 198ms/step - loss: 0.7969 - accuracy: 0.7375\n",
      "Epoch 2/10\n",
      "63/63 [==============================] - 12s 184ms/step - loss: 0.4012 - accuracy: 0.8295\n",
      "Epoch 3/10\n",
      "63/63 [==============================] - 12s 182ms/step - loss: 0.2562 - accuracy: 0.8980\n",
      "Epoch 4/10\n",
      "63/63 [==============================] - 12s 182ms/step - loss: 0.1668 - accuracy: 0.9425\n",
      "Epoch 5/10\n",
      "63/63 [==============================] - 12s 182ms/step - loss: 0.1148 - accuracy: 0.9540\n",
      "Epoch 6/10\n",
      "63/63 [==============================] - 12s 184ms/step - loss: 0.0739 - accuracy: 0.9745\n",
      "Epoch 7/10\n",
      "63/63 [==============================] - 12s 189ms/step - loss: 0.0725 - accuracy: 0.9725\n",
      "Epoch 8/10\n",
      "63/63 [==============================] - 12s 186ms/step - loss: 0.0402 - accuracy: 0.9850\n",
      "Epoch 9/10\n",
      "63/63 [==============================] - 12s 186ms/step - loss: 0.0977 - accuracy: 0.9660\n",
      "Epoch 10/10\n",
      "63/63 [==============================] - 12s 186ms/step - loss: 0.0510 - accuracy: 0.9850\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff9e373bc10>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_dataset, epochs=5, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8lAR9nCwIhND"
   },
   "outputs": [],
   "source": [
    "# Some code to help with predictions as now we are using \n",
    "# the image_dataset_from_directory function which generated\n",
    "# a tf.data.Dataset\n",
    "predictions = []\n",
    "labels =  []\n",
    "\n",
    "for x, y in validation_dataset:\n",
    "  predictions.extend(np.argmax(model.predict(x), axis=-1))\n",
    "  labels.extend(np.argmax(y.numpy(), axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UnvoWjczJUgk",
    "outputId": "a062a2f7-d8f7-48cc-b9bf-1cffd93a96a2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89.2"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(predictions,labels)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2gwWdvDmJeE9"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
