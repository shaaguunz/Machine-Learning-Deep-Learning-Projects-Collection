{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zs3Vxo5dmP7j"
   },
   "source": [
    "## Image classification AlexNet\n",
    "\n",
    "***NOTE***\n",
    "\n",
    "Be sure to use hardware acceleration to use the GPU. Click on `Runtime`, change `runtime type`, and select `GPU` for the *hardware accelerator* option."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5FUHcE89LT3x"
   },
   "source": [
    "* AlexNet, which employed an 8-layer CNN,\n",
    "won the ImageNet Large Scale Visual Recognition Challenge 2012\n",
    "by a large margin\n",
    "\n",
    "* This network showed, for the first time,\n",
    "that the features obtained by learning can transcend manually-designed features, breaking the previous paradigm in computer vision.\n",
    "\n",
    "* The architectures of AlexNet and LeNet (see below) are somewhat similar\n",
    "\n",
    "* There are also significant differences between AlexNet and LeNet.\n",
    "\n",
    "* First, AlexNet is much deeper than the comparatively small LeNet5.\n",
    "AlexNet consists of eight layers in the feature extractor,\n",
    "two fully connected hidden layers, and one fully connected output layer.\n",
    "\n",
    "* Second, AlexNet used the ReLU instead of the sigmoid\n",
    "as its activation function.\n",
    "\n",
    "* In AlexNet's first layer, the convolution window shape is $11\\times11$.\n",
    "Since the images in ImageNet are eight times higher and wider\n",
    "than the MNIST images,\n",
    "objects in ImageNet data tend to occupy more pixels with more visual detail.\n",
    "Consequently, a larger convolution window is needed to capture the object.\n",
    "\n",
    "* ReLU activation function makes model training easier when using different parameter initialization methods. This is because, when the output of the sigmoid activation function is very close to 0 or 1, the gradient of these regions is almost 0, so that backpropagation cannot continue to update some of the model parameters. In contrast, the gradient of the ReLU activation function in the positive interval is always 1 \n",
    "\n",
    "* To augment the data even further, the training loop of AlexNet\n",
    "added a great deal of image augmentation,\n",
    "such as flipping, clipping, and color changes.\n",
    "\n",
    "![From LeNet (left) to AlexNet (right).](http://d2l.ai/_images/alexnet.svg)\n",
    "\n",
    "(left LeNet5, right AlexNet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gpvo-bqTmP7m"
   },
   "source": [
    "## Imports first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nvCXvXq5mP7p",
    "outputId": "834b3651-341d-44d5-b50b-c47c4d7775d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.2\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.datasets import fashion_mnist\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import np_utils\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X1GTR35cmP7v"
   },
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uQ_KjFJomP7x",
    "outputId": "f47b0586-e283-48a0-dc11-947dc9895b13"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
      "29515/29515 [==============================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
      "26421880/26421880 [==============================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "5148/5148 [==============================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "4422102/4422102 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "(X_train, Y_train), (X_test, Y_test) = tf.keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E-Lw_bPQKQFX"
   },
   "source": [
    "## View the shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ueyWl-aUmP72",
    "outputId": "2a1a9806-becb-4207-97c4-c4b79030ee7a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape :  (60000, 28, 28) (60000,)\n"
     ]
    }
   ],
   "source": [
    "print('Training data shape : ', X_train.shape, Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3bsoluyzBOYR",
    "outputId": "28bc6e18-d5cc-401d-b595-65748eda13df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing data shape :  (10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "print('Testing data shape : ', X_test.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z51sdOntmP78"
   },
   "source": [
    "## Find the unique numbers from the train labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o29O_gUTmP79",
    "outputId": "a015e2f1-29e4-4b0f-b4ac-4b02dcb0e848"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of outputs :  10\n",
      "Output classes :  [0 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "classes = np.unique(Y_train)\n",
    "nClasses = len(classes)\n",
    "print('Total number of outputs : ', nClasses)\n",
    "print('Output classes : ', classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GMMjLgbimP8B"
   },
   "source": [
    "## Plot some of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 335
    },
    "id": "qQpW4rajmP8C",
    "outputId": "73cb2407-f511-4c07-a191-981b0675592a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Ground Truth : 1')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_point = 15\n",
    "\n",
    "plt.figure(figsize=[10,5])\n",
    " \n",
    "# Display the first image in training data\n",
    "plt.subplot(121)\n",
    "plt.imshow(X_train[data_point,:,:], cmap='gray')\n",
    "plt.title(\"Ground Truth : {}\".format(Y_train[data_point]))\n",
    " \n",
    "# Display the first image in testing data\n",
    "plt.subplot(122)\n",
    "plt.imshow(X_test[data_point,:,:], cmap='gray')\n",
    "plt.title(\"Ground Truth : {}\".format(Y_test[data_point]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BA_mGK_NVHwn"
   },
   "source": [
    "## Reshape needed\n",
    "\n",
    "Keras wants to know the depth of an image. \n",
    "\n",
    "For CNNS, Keras wants the format of the data as follows: [batches, width, height, depth]. \n",
    "\n",
    "In this case the colour channel/depth of the images is 1. Currently the shape is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TBbn1qONB0M8",
    "outputId": "c958b37b-33fd-40d9-bed1-8c7b780b805b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FmTJdq8LRDsx",
    "outputId": "e400ea23-1bcd-4b36-ee96-d64e73c76f12"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a55ZpEbCB6kQ"
   },
   "source": [
    "But this doesn't have a depth value. So we can reshape it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D8HTp2YHVH4_"
   },
   "outputs": [],
   "source": [
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], X_train.shape[2], 1))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], X_test.shape[2], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pvHP86fjRU8z",
    "outputId": "85fcc519-a5a5-4fdb-911a-0510727e2474"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9AMa4C0CRWb9",
    "outputId": "c17f28c7-3308-4d9c-d272-88c09786349d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-lQP7CElWVfe"
   },
   "source": [
    "## View the shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5QKOvMPaWVfh",
    "outputId": "42b86c17-533d-4216-a4b1-5e50d722c886"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape :  (60000, 28, 28, 1) (60000,)\n"
     ]
    }
   ],
   "source": [
    "print('Training data shape : ', X_train.shape, Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zzGxSUONCRb2",
    "outputId": "8bbd5472-0093-42e4-befd-b77d2363b65a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing data shape :  (10000, 28, 28, 1) (10000,)\n"
     ]
    }
   ],
   "source": [
    "print('Testing data shape : ', X_test.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UfClFp-6K7P6"
   },
   "source": [
    "## Convert from categorical labels to one-hot encoded vectors\n",
    "\n",
    "In this case there are 10 classes so we can tell the function to convert into a vector of length 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i3xjsPnVmP8j"
   },
   "outputs": [],
   "source": [
    "Y_train = np_utils.to_categorical(Y_train, 10)\n",
    "Y_test = np_utils.to_categorical(Y_test, 10)\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q7LVPnt1QPQM"
   },
   "source": [
    "## Small twist!\n",
    "\n",
    "API: https://www.tensorflow.org/api_docs/python/tf/data/Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PQNnZHhNSEKW"
   },
   "outputs": [],
   "source": [
    "train_ds = tf.data.Dataset.from_tensor_slices((X_train, Y_train))\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aHvmE76ySEMx"
   },
   "outputs": [],
   "source": [
    "def resize_images(image, label):\n",
    "    # Normalize images to have a mean of 0 and standard deviation of 1\n",
    "    image = tf.image.per_image_standardization(image)\n",
    "\n",
    "    image = tf.image.resize(image, (224,224))\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fqEzyUPLSOdv"
   },
   "outputs": [],
   "source": [
    "train_ds = (train_ds\n",
    "                  .map(resize_images)\n",
    "                  .shuffle(buffer_size=10000)\n",
    "                  .batch(batch_size=64, drop_remainder=True))\n",
    "test_ds = (test_ds\n",
    "                  .map(resize_images)\n",
    "                  .batch(batch_size=10, drop_remainder=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VungsdeHmP8u"
   },
   "source": [
    "## Create a CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gozmsPxhmP8v"
   },
   "outputs": [],
   "source": [
    "def baseline_model():\n",
    "    # create model\n",
    "    model = tf.keras.Sequential()\n",
    "\n",
    "    model.add(tf.keras.layers.Conv2D(filters=96, kernel_size=11, strides=4,\n",
    "                                   activation='relu', input_shape=(224,224,1)))\n",
    "    model.add(tf.keras.layers.MaxPool2D(pool_size=3, strides=2))\n",
    "    model.add(tf.keras.layers.Conv2D(filters=256, kernel_size=5, padding='same',\n",
    "                                   activation='relu'))\n",
    "    model.add(tf.keras.layers.MaxPool2D(pool_size=3, strides=2))\n",
    "    model.add(tf.keras.layers.Conv2D(filters=384, kernel_size=3, padding='same',\n",
    "                                   activation='relu'))\n",
    "    model.add(tf.keras.layers.Conv2D(filters=384, kernel_size=3, padding='same',\n",
    "                                   activation='relu'))\n",
    "    model.add(tf.keras.layers.Conv2D(filters=256, kernel_size=3, padding='same',\n",
    "                                   activation='relu'))\n",
    "    model.add(tf.keras.layers.MaxPool2D(pool_size=3, strides=2))\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(4096, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dropout(0.5))\n",
    "    model.add(tf.keras.layers.Dense(4096, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dropout(0.5))\n",
    "    model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "             optimizer='adam',\n",
    "             metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q03EcUrxmP8x"
   },
   "outputs": [],
   "source": [
    "model = baseline_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bUN6K31smP80"
   },
   "source": [
    "## Determine the number of trainable parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_DxDanOHmP80",
    "outputId": "df2a6b0b-9472-4bce-9351-0c0df50bbd03"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 54, 54, 96)        11712     \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 26, 26, 96)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 26, 26, 256)       614656    \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 12, 12, 256)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 12, 12, 384)       885120    \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 12, 12, 384)       1327488   \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 12, 12, 256)       884992    \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 5, 5, 256)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 6400)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 4096)              26218496  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4096)              16781312  \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                40970     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 46,764,746\n",
      "Trainable params: 46,764,746\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ifPs0mftmP84"
   },
   "source": [
    "## Begin training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j8RZc1rhmP84",
    "outputId": "6f8280d4-845e-4624-88f8-e52717448f52"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "937/937 [==============================] - 81s 67ms/step - loss: 0.5242 - accuracy: 0.8105\n",
      "Epoch 2/2\n",
      "937/937 [==============================] - 65s 67ms/step - loss: 0.3500 - accuracy: 0.8739\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3a60540950>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_ds, epochs=2, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_j9LecHgmP8_"
   },
   "source": [
    "## Predict on all the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7TtfkDWjmP8_",
    "outputId": "d5544571-a637-4ebb-8031-827f38c99d41"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 6s 6ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b_zM7W80cFhJ",
    "outputId": "f98a598a-3174-462a-bb14-366b1742edbf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0abcDBFmcCz5"
   },
   "outputs": [],
   "source": [
    "correct_values = np.argmax(Y_test,axis=-1)\n",
    "predicted_classes = np.argmax(predictions,axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N7keRohxmP9H",
    "outputId": "d67f492b-efc1-4284-8079-fa960ba760f6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87.52"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(predicted_classes,correct_values)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-1Ik7Odwj9L6"
   },
   "source": [
    "More efficient:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "agkf9IKkiotI"
   },
   "outputs": [],
   "source": [
    "targets = []\n",
    "for x,y in test_ds.as_numpy_iterator():\n",
    "  targets.extend(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5n-nlHvkjhkL",
    "outputId": "2ef2b5f6-b0b2-4511-d15c-700d5279620a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.asarray(targets).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AnlUWwWmirtl",
    "outputId": "4eaf46aa-4d81-4ea9-afa7-81b28841f509"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87.52"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(predicted_classes,np.argmax(targets,axis=-1))*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pci1FMrJcuSs"
   },
   "source": [
    "## Tasks:\n",
    "\n",
    "* Without removing any layers, reduce the number of trainable parameters. How does this compare in testing performance? Try this a few times to get the best performance you can.\n",
    "\n",
    "* How did you decide on what to change?\n",
    "\n",
    "* What would make this process faster? \n",
    "\n",
    "* How do you think this relates to implementing deep learning models in practice? What are some of the challenges?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6lPFztVMj3d6"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
