{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da55336",
   "metadata": {
    "id": "3da55336"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Dropout, Flatten, BatchNormalization\n",
    "import tensorflow as tf\n",
    "from keras.datasets import fashion_mnist\n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0782142b",
   "metadata": {
    "id": "0782142b",
    "origin_pos": 1
   },
   "source": [
    "# Densely Connected Networks (DenseNet)\n",
    "\n",
    "ResNet significantly changed the view of how to parametrize the functions in deep networks. *DenseNet* (dense convolutional network) is to some extent the logical extension of this.\n",
    "As a result,\n",
    "DenseNet \n",
    "is characterized by\n",
    "both the connectivity pattern where\n",
    "each layer connects to all the preceding layers\n",
    "and the concatenation operation (rather than the addition operator in ResNet) to preserve and reuse features\n",
    "from earlier layers.\n",
    "\n",
    "\n",
    "## From ResNet to DenseNet\n",
    "\n",
    "ResNet decomposes functions into\n",
    "\n",
    "$$f(\\mathbf{x}) = \\mathbf{x} + g(\\mathbf{x}).$$\n",
    "\n",
    "That is, ResNet decomposes $f$ into a simple linear term and a more complex\n",
    "nonlinear one.\n",
    "What if we want to capture (not necessarily add) information beyond two terms?\n",
    "One solution was\n",
    "DenseNet.\n",
    "\n",
    "![The main difference between ResNet (left) and DenseNet (right) in cross-layer connections: use of addition and use of concatenation. ](https://github.com/d2l-ai/d2l-tensorflow-colab/blob/master/img/densenet-block.svg?raw=1)\n",
    "\n",
    "\n",
    "As shown in the figure, the key difference between ResNet and DenseNet is that in the latter case outputs are *concatenated* (denoted by $[,]$) rather than added.\n",
    "As a result, we perform a mapping from $\\mathbf{x}$ to its values after applying an increasingly complex sequence of functions:\n",
    "\n",
    "$$\\mathbf{x} \\to \\left[\n",
    "\\mathbf{x},\n",
    "f_1(\\mathbf{x}),\n",
    "f_2([\\mathbf{x}, f_1(\\mathbf{x})]), f_3([\\mathbf{x}, f_1(\\mathbf{x}), f_2([\\mathbf{x}, f_1(\\mathbf{x})])]), \\ldots\\right].$$\n",
    "\n",
    "In the end, all these functions are combined in MLP to reduce the number of features again. In terms of implementation this is quite simple:\n",
    "rather than adding terms, we concatenate them. The name DenseNet arises from the fact that the dependency graph between variables becomes quite dense. The last layer of such a chain is densely connected to all previous layers. The dense connections are shown below.\n",
    "\n",
    "![Dense connections in DenseNet.](http://d2l.ai/_images/densenet.svg)\n",
    "\n",
    "The main components that compose a DenseNet are ***dense blocks*** and ***transition layers***. The former define how the inputs and outputs are concatenated, while the latter control the number of channels so that it is not too large.\n",
    "\n",
    "The difference between DenseNet and ResNet are shown below.\n",
    "![](https://i.imgur.com/z3n0Afg.png)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## **Dense Blocks**\n",
    "\n",
    "First we go step by step using cells, and then we write it as a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gObXt3bCD2xE",
   "metadata": {
    "id": "gObXt3bCD2xE"
   },
   "outputs": [],
   "source": [
    "# Define some input, with 4 tensors of 8x8x3\n",
    "X = tf.random.uniform((4, 8, 8, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "OeCkBFgSDSu6",
   "metadata": {
    "id": "OeCkBFgSDSu6"
   },
   "outputs": [],
   "source": [
    "# The first operation is to normalise the input\n",
    "bn = tf.keras.layers.BatchNormalization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Ozl3NwZIDSzW",
   "metadata": {
    "id": "Ozl3NwZIDSzW"
   },
   "outputs": [],
   "source": [
    "# The second operation is to apply convolution and non-linear activation\n",
    "conv = tf.keras.layers.Conv2D(\n",
    "            filters=16, kernel_size=(3, 3), padding='same', activation = 'relu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nWBH9Y7tDS1t",
   "metadata": {
    "id": "nWBH9Y7tDS1t"
   },
   "outputs": [],
   "source": [
    "# There are the two operations\n",
    "listLayers = [bn, conv]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "EHH1PJl0Dj-e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EHH1PJl0Dj-e",
    "outputId": "dce65b23-540b-4d19-f4c4-dd3fc5ecddbd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x7f9a65ab2690>\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x7f9a65741ed0>\n"
     ]
    }
   ],
   "source": [
    "# First we set y to be the input X\n",
    "y = X\n",
    "\n",
    "# Then we iterate over the operations and compose them into a chain\n",
    "for layer in listLayers:\n",
    "    print (layer)\n",
    "    y = layer(y)\n",
    "\n",
    "# See below, batch normalisation is applied to X, and then\n",
    "# conv2d is applied to: batch normalisation which is applied to X\n",
    "# so basically: conv2d(batchNorm(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "VzxmsVESDkC1",
   "metadata": {
    "id": "VzxmsVESDkC1"
   },
   "outputs": [],
   "source": [
    "# Now we concatenate the input X with the output of the dense block y\n",
    "y = tf.keras.layers.concatenate([X,y], axis=-1)\n",
    "# y = [X, conv2d(batchNorm(X))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "j59VGhpaF7bb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j59VGhpaF7bb",
    "outputId": "f431eaac-2b1c-4735-9de3-a303aab7a2f0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([4, 8, 8, 19])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the width and heigh are unchanged, makes sense since we used same padding\n",
    "# we created 16 filters so this means we have 16 feature maps, and X had a depth of\n",
    "# 3, so 16 + 3 = 19.\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f3750e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-13T11:47:13.654874Z",
     "iopub.status.busy": "2022-07-13T11:47:13.654187Z",
     "iopub.status.idle": "2022-07-13T11:47:16.480408Z",
     "shell.execute_reply": "2022-07-13T11:47:16.479468Z"
    },
    "id": "09f3750e",
    "origin_pos": 4,
    "tab": [
     "tensorflow"
    ]
   },
   "outputs": [],
   "source": [
    "class ConvBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_channels):\n",
    "        super(ConvBlock, self).__init__()\n",
    "\n",
    "        # The batch normalisation layer\n",
    "        self.bn = tf.keras.layers.BatchNormalization()\n",
    "\n",
    "        # A relu activation\n",
    "        self.relu = tf.keras.layers.ReLU()\n",
    "\n",
    "        # A linear convolution\n",
    "        self.conv = tf.keras.layers.Conv2D(\n",
    "            filters=num_channels, kernel_size=(3, 3), padding='same')\n",
    "        \n",
    "        self.conv2 = tf.keras.layers.Conv2D(\n",
    "            filters=num_channels, kernel_size=(3, 3), padding='same')\n",
    "\n",
    "\n",
    "        # Order of operations: BN, then relu, then conv2d\n",
    "        self.listLayers = [self.bn, self.relu, self.conv, self.conv2]\n",
    "\n",
    "    def call(self, x):\n",
    "\n",
    "        # First set y to be the input x\n",
    "        y = x\n",
    "\n",
    "        # Then apply BN, ReLU and then conv2d\n",
    "        for layer in self.listLayers.layers:\n",
    "            y = layer(y)\n",
    "            # BN([X, Conv2d(ReLU(BN(X)))])\n",
    "            # Relu(BN([X, Conv2d(ReLU(BN(X)))]))\n",
    "            # Conv(Relu(BN([X, Conv2d(ReLU(BN(X)))])))\n",
    "\n",
    "        # Finally, concantenate X and the output y\n",
    "        # meaning we get: [X, Conv2d(ReLU(BN(X)))]\n",
    "        y = tf.keras.layers.concatenate([x,y], axis=-1)\n",
    "        # [X, Conv2d(ReLU(BN(X)))], Conv(Relu(BN([X, Conv2d(ReLU(BN(X)))])))\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b562f8",
   "metadata": {
    "id": "f4b562f8",
    "origin_pos": 5
   },
   "source": [
    "A *dense block* consists of multiple convolution blocks, each using the same number of output channels. In the forward propagation, however, we concatenate the input and output of each convolution block on the channel dimension.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588ac181",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-13T11:47:16.484890Z",
     "iopub.status.busy": "2022-07-13T11:47:16.484244Z",
     "iopub.status.idle": "2022-07-13T11:47:16.489879Z",
     "shell.execute_reply": "2022-07-13T11:47:16.489108Z"
    },
    "id": "588ac181",
    "origin_pos": 8,
    "tab": [
     "tensorflow"
    ]
   },
   "outputs": [],
   "source": [
    "class DenseBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_convs, num_channels):\n",
    "        super(DenseBlock, self).__init__()\n",
    "        self.listLayers = []\n",
    "\n",
    "        # Here we create a number of ConvBlocks (see above)\n",
    "        # Here we simply create and append them to this list\n",
    "        for _ in range(num_convs):\n",
    "            self.listLayers.append(ConvBlock(num_channels))\n",
    "            # [ConvBlock(10), ConvBLock(10)]\n",
    "\n",
    "    def call(self, x):\n",
    "\n",
    "        # Now we create the dense block by chaining together\n",
    "        # the various smaller ConvBlocks! So it would look like\n",
    "        # ConvBlock(ConvBlock(X)) in the case of num_conv = 2\n",
    "        # which expands to: [X, Conv2d(ReLU(BN([X, Conv2d(ReLU(BN(X))))))]]\n",
    "        # the above is a little messy! But the first block \n",
    "        # will create [X, [X, Conv2d(ReLU(BN(X)))] and then we do this one more time\n",
    "        for layer in self.listLayers.layers:\n",
    "            x = layer(x)\n",
    "            # x = [X, Conv2d(ReLU(BN(X)))]\n",
    "            # ConvBLock([X, Conv2d(ReLU(BN(X)))])\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f152073",
   "metadata": {
    "id": "7f152073",
    "origin_pos": 9
   },
   "source": [
    "In the following example,\n",
    "we [**define a `DenseBlock` instance**] with 2 convolution blocks of 10 output channels.\n",
    "When using an input with 3 channels, we will get an output with $23$ channels. \n",
    "\n",
    "[X, Conv2d(ReLU(BN(X)))]\n",
    "\n",
    "[3, 10] which gets concatenated = 13\n",
    "\n",
    "[13, 10] which gets concatenated = 23\n",
    "\n",
    "\n",
    "The number of convolution block channels controls the growth in the number of output channels relative to the number of input channels. This is also referred to as the *growth rate*.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0fef4d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-07-13T11:47:16.493256Z",
     "iopub.status.busy": "2022-07-13T11:47:16.492810Z",
     "iopub.status.idle": "2022-07-13T11:47:20.224835Z",
     "shell.execute_reply": "2022-07-13T11:47:20.223948Z"
    },
    "id": "cf0fef4d",
    "origin_pos": 10,
    "outputId": "4738eee5-3abc-42d4-ba9d-37a49022cc6b",
    "tab": [
     "tensorflow"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([4, 8, 8, 23])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blk = DenseBlock(2, 10)\n",
    "X = tf.random.uniform((4, 8, 8, 3))\n",
    "Y = blk(X)\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337192a5",
   "metadata": {
    "id": "337192a5",
    "origin_pos": 11
   },
   "source": [
    "## **Transition Layers**\n",
    "\n",
    "* Since each dense block will increase the number of channels, adding too many of them will lead to an excessively complex model. \n",
    "\n",
    "* A *transition layer* is used to control the complexity of the model. \n",
    "\n",
    "* It reduces the number of channels by using the $1\\times 1$ convolutional layer and halves the height and width of the average pooling layer with a stride of 2, further reducing the complexity of the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b230f9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-13T11:47:20.228731Z",
     "iopub.status.busy": "2022-07-13T11:47:20.228130Z",
     "iopub.status.idle": "2022-07-13T11:47:20.234440Z",
     "shell.execute_reply": "2022-07-13T11:47:20.233601Z"
    },
    "id": "d1b230f9",
    "origin_pos": 14,
    "tab": [
     "tensorflow"
    ]
   },
   "outputs": [],
   "source": [
    "class TransitionBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_channels, **kwargs):\n",
    "        super(TransitionBlock, self).__init__(**kwargs)\n",
    "        self.batch_norm = tf.keras.layers.BatchNormalization()\n",
    "        self.relu = tf.keras.layers.ReLU()\n",
    "\n",
    "        # 1x1 convolution will reduce the depth of the tensor\n",
    "        self.conv = tf.keras.layers.Conv2D(num_channels, kernel_size=1)\n",
    "\n",
    "        # Reduce the width and height\n",
    "        self.avg_pool = tf.keras.layers.AvgPool2D(pool_size=2, strides=2)\n",
    "\n",
    "    def call(self, x):\n",
    "\n",
    "        # batch norm first\n",
    "        x = self.batch_norm(x)\n",
    "\n",
    "        # then relu\n",
    "        x = self.relu(x)\n",
    "\n",
    "        # then conv\n",
    "        x = self.conv(x)\n",
    "\n",
    "        # then conv\n",
    "        return self.avg_pool(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b214d3b",
   "metadata": {
    "id": "1b214d3b",
    "origin_pos": 15
   },
   "source": [
    "[**Apply a transition layer**] with 10 channels to the output of the dense block in the previous example.  This reduces the number of output channels to 10, and halves the height and width.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d526c5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-07-13T11:47:20.237921Z",
     "iopub.status.busy": "2022-07-13T11:47:20.237370Z",
     "iopub.status.idle": "2022-07-13T11:47:20.255858Z",
     "shell.execute_reply": "2022-07-13T11:47:20.255010Z"
    },
    "id": "39d526c5",
    "origin_pos": 18,
    "outputId": "b2d3877c-74d8-47c1-bea8-3c597238f4f9",
    "tab": [
     "tensorflow"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([4, 4, 4, 10])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blk = TransitionBlock(10)\n",
    "blk(Y).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e11014b",
   "metadata": {
    "id": "8e11014b",
    "origin_pos": 19
   },
   "source": [
    "## **DenseNet Model**\n",
    "\n",
    "Next, we will construct a DenseNet model. DenseNet first uses the same single convolutional layer and max-pooling layer as in ResNet.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b05de8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-13T11:47:20.259691Z",
     "iopub.status.busy": "2022-07-13T11:47:20.258942Z",
     "iopub.status.idle": "2022-07-13T11:47:20.264138Z",
     "shell.execute_reply": "2022-07-13T11:47:20.263352Z"
    },
    "id": "23b05de8",
    "origin_pos": 20,
    "tab": [
     "tensorflow"
    ]
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Conv2D(\n",
    "    64, kernel_size=7, strides=2, padding='same', input_shape=(96,96,1)))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.ReLU())\n",
    "model.add(tf.keras.layers.MaxPool2D(pool_size=3, strides=2, padding='same'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d9b6e7",
   "metadata": {
    "id": "d0d9b6e7",
    "origin_pos": 21
   },
   "source": [
    "* Then, similar to the four modules made up of residual blocks that ResNet uses,\n",
    "DenseNet uses four dense blocks.\n",
    "Similar to ResNet, we can set the number of convolutional layers used in each dense block. \n",
    "\n",
    "* Here, we set it to 4, consistent with the ResNet-18 model. \n",
    "\n",
    "* Furthermore, we set the number of channels (i.e., growth rate) for the convolutional layers in the dense block to 32, so 128 channels will be added to each dense block.\n",
    "\n",
    "* In ResNet, the height and width are reduced between each module by a residual block with a stride of 2. \n",
    "\n",
    "* Here, we use the transition layer to halve the height and width and halve the number of channels. Similar to ResNet, a global pooling layer and a fully connected layer are connected at the end to produce the output.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ca8778",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-13T11:47:20.268147Z",
     "iopub.status.busy": "2022-07-13T11:47:20.267467Z",
     "iopub.status.idle": "2022-07-13T11:47:20.274267Z",
     "shell.execute_reply": "2022-07-13T11:47:20.273480Z"
    },
    "id": "d9ca8778",
    "origin_pos": 22,
    "tab": [
     "tensorflow"
    ]
   },
   "outputs": [],
   "source": [
    "num_channels=64 \n",
    "growth_rate=32\n",
    "\n",
    "# First Dense block\n",
    "model.add(DenseBlock(4, growth_rate))\n",
    "num_channels = num_channels + (4 * growth_rate)\n",
    "num_channels = num_channels / 2\n",
    "model.add(TransitionBlock(num_channels))\n",
    "\n",
    "# Second Dense block\n",
    "model.add(DenseBlock(4, growth_rate))\n",
    "num_channels = num_channels + (4 * growth_rate)\n",
    "num_channels = num_channels / 2\n",
    "model.add(TransitionBlock(num_channels))\n",
    "\n",
    "# Third Dense block\n",
    "model.add(DenseBlock(4, growth_rate))\n",
    "num_channels = num_channels + (4 * growth_rate)\n",
    "num_channels = num_channels / 2\n",
    "model.add(TransitionBlock(num_channels))\n",
    "\n",
    "# Forth Dense block\n",
    "model.add(DenseBlock(4, growth_rate))\n",
    "\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.ReLU())\n",
    "model.add(tf.keras.layers.GlobalAvgPool2D())\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(10, activation = \"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5kYUSEeePNdl",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5kYUSEeePNdl",
    "outputId": "95b950b5-673a-4c0d-809e-c75dddb8eab0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_4 (Conv2D)           (None, 48, 48, 64)        3200      \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 48, 48, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " re_lu_3 (ReLU)              (None, 48, 48, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 24, 24, 64)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dense_block_1 (DenseBlock)  (None, 24, 24, 192)       130944    \n",
      "                                                                 \n",
      " transition_block_1 (Transit  (None, 12, 12, 96)       19296     \n",
      " ionBlock)                                                       \n",
      "                                                                 \n",
      " dense_block_2 (DenseBlock)  (None, 12, 12, 224)       168320    \n",
      "                                                                 \n",
      " transition_block_2 (Transit  (None, 6, 6, 112)        26096     \n",
      " ionBlock)                                                       \n",
      "                                                                 \n",
      " dense_block_3 (DenseBlock)  (None, 6, 6, 240)         187008    \n",
      "                                                                 \n",
      " transition_block_3 (Transit  (None, 3, 3, 120)        29880     \n",
      " ionBlock)                                                       \n",
      "                                                                 \n",
      " dense_block_4 (DenseBlock)  (None, 3, 3, 248)         196352    \n",
      "                                                                 \n",
      " batch_normalization_24 (Bat  (None, 3, 3, 248)        992       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " re_lu_23 (ReLU)             (None, 3, 3, 248)         0         \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 248)              0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 248)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                2490      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 764,834\n",
      "Trainable params: 758,226\n",
      "Non-trainable params: 6,608\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "F3qDRHsrTvEY",
   "metadata": {
    "id": "F3qDRHsrTvEY"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "X1GTR35cmP7v",
   "metadata": {
    "id": "X1GTR35cmP7v"
   },
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "uQ_KjFJomP7x",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uQ_KjFJomP7x",
    "outputId": "ad3147d7-b126-4f1b-c436-332a36a184b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
      "29515/29515 [==============================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
      "26421880/26421880 [==============================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "5148/5148 [==============================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "4422102/4422102 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "(X_train, Y_train), (X_test, Y_test) = tf.keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "z51sdOntmP78",
   "metadata": {
    "id": "z51sdOntmP78"
   },
   "source": [
    "## Find the unique numbers from the train labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "o29O_gUTmP79",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o29O_gUTmP79",
    "outputId": "2fccdfdf-de0e-4037-8a78-9d63999cfe56"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of outputs :  10\n",
      "Output classes :  [0 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "classes = np.unique(Y_train)\n",
    "nClasses = len(classes)\n",
    "print('Total number of outputs : ', nClasses)\n",
    "print('Output classes : ', classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "BA_mGK_NVHwn",
   "metadata": {
    "id": "BA_mGK_NVHwn"
   },
   "source": [
    "## Reshape needed\n",
    "\n",
    "Keras wants to know the depth of an image. \n",
    "\n",
    "For CNNS, Keras wants the format of the data as follows: [batches, width, height, depth]. \n",
    "\n",
    "In this case the colour channel/depth of the images is 1. Currently the shape is:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55ZpEbCB6kQ",
   "metadata": {
    "id": "a55ZpEbCB6kQ"
   },
   "source": [
    "But this doesn't have a depth value. So we can reshape it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "D8HTp2YHVH4_",
   "metadata": {
    "id": "D8HTp2YHVH4_"
   },
   "outputs": [],
   "source": [
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], X_train.shape[2], 1))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], X_test.shape[2], 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "UfClFp-6K7P6",
   "metadata": {
    "id": "UfClFp-6K7P6"
   },
   "source": [
    "## Convert from categorical labels to one-hot encoded vectors\n",
    "\n",
    "In this case there are 10 classes so we can tell the function to convert into a vector of length 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "i3xjsPnVmP8j",
   "metadata": {
    "id": "i3xjsPnVmP8j"
   },
   "outputs": [],
   "source": [
    "Y_train = np_utils.to_categorical(Y_train, 10)\n",
    "Y_test = np_utils.to_categorical(Y_test, 10)\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Q7LVPnt1QPQM",
   "metadata": {
    "id": "Q7LVPnt1QPQM"
   },
   "source": [
    "## Small twist!\n",
    "\n",
    "API: https://www.tensorflow.org/api_docs/python/tf/data/Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "PQNnZHhNSEKW",
   "metadata": {
    "id": "PQNnZHhNSEKW"
   },
   "outputs": [],
   "source": [
    "train_ds = tf.data.Dataset.from_tensor_slices((X_train, Y_train))\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aHvmE76ySEMx",
   "metadata": {
    "id": "aHvmE76ySEMx"
   },
   "outputs": [],
   "source": [
    "def resize_images(image, label):\n",
    "    # Normalize images to have a mean of 0 and standard deviation of 1\n",
    "    image = tf.image.per_image_standardization(image)\n",
    "\n",
    "    image = tf.image.resize(image, (96,96))\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fqEzyUPLSOdv",
   "metadata": {
    "id": "fqEzyUPLSOdv"
   },
   "outputs": [],
   "source": [
    "train_ds = (train_ds\n",
    "                  .map(resize_images)\n",
    "                  .shuffle(buffer_size=10000)\n",
    "                  .batch(batch_size=64, drop_remainder=True))\n",
    "test_ds = (test_ds\n",
    "                  .map(resize_images)\n",
    "                  .batch(batch_size=32, drop_remainder=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gozmsPxhmP8v",
   "metadata": {
    "id": "gozmsPxhmP8v"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "             optimizer=tf.keras.optimizers.Adam(learning_rate=0.005),\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ifPs0mftmP84",
   "metadata": {
    "id": "ifPs0mftmP84"
   },
   "source": [
    "## Begin training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "j8RZc1rhmP84",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j8RZc1rhmP84",
    "outputId": "0491c8da-d4a2-45f1-eda2-9d58f6665993"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "937/937 [==============================] - 46s 43ms/step - loss: 0.4510 - accuracy: 0.8335\n",
      "Epoch 2/2\n",
      "937/937 [==============================] - 42s 44ms/step - loss: 0.2895 - accuracy: 0.8945\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9a502fbbd0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_ds, epochs=2, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "_j9LecHgmP8_",
   "metadata": {
    "id": "_j9LecHgmP8_"
   },
   "source": [
    "## Predict on all the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7TtfkDWjmP8_",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7TtfkDWjmP8_",
    "outputId": "2b92af06-a480-4165-d7f9-2729a15936a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 3s 8ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b_zM7W80cFhJ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b_zM7W80cFhJ",
    "outputId": "b8f5a680-4914-4636-f339-de9cc093982b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0abcDBFmcCz5",
   "metadata": {
    "id": "0abcDBFmcCz5"
   },
   "outputs": [],
   "source": [
    "correct_values = np.argmax(Y_test,axis=-1)\n",
    "predicted_classes = np.argmax(predictions,axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "N7keRohxmP9H",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N7keRohxmP9H",
    "outputId": "7f3cb3a6-2890-4707-8d5f-664857e7bb52"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86.26"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(predicted_classes,correct_values)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rIBK-YiBUkeP",
   "metadata": {
    "id": "rIBK-YiBUkeP"
   },
   "source": [
    "# Tasks\n",
    "\n",
    "* explore different architecture structures by modifying the number of blocks\n",
    "\n",
    "* attempt to modify the Conv block\n",
    "\n",
    "* attempt to modify the transition block\n",
    "\n",
    "* Here we apply ReLU after batch norm, apply it before like we did with ResNet\n",
    "\n",
    "* Modify the overall network so that not every layer is connected to every previous layer, but rather it skips between two consecutive layers. So layer i is connected to i-2.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sT3V263AT1bQ",
   "metadata": {
    "id": "sT3V263AT1bQ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
