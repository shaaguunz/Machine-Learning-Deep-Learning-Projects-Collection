{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zs3Vxo5dmP7j"
   },
   "source": [
    "## Image classification GoogLeNet\n",
    "\n",
    "***NOTE***\n",
    "\n",
    "Be sure to use hardware acceleration to use the GPU. Click on `Runtime`, change `runtime type`, and select `GPU` for the *hardware accelerator* option."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5FUHcE89LT3x"
   },
   "source": [
    "* major benefits of a very deep network is that it can represent very complex functions.\n",
    "\n",
    "* However, a huge barrier to training them is vanishing gradients: very deep networks often have a gradient signal that goes to zero quickly, thus making gradient descent prohibitively slow.\n",
    "\n",
    "* during gradient descent, as we backprop from the final layer back to the first layer, we are multiplying by the weight matrix on each step. If the gradients are small, due to large number of multiplications, the gradient can decrease exponentially quickly to zero\n",
    "\n",
    "* as the number of layers increase from 20 to 56 (as shown below), even after thousands of iterations, training error was worse for a 56 layer compared to a 20 layer network\n",
    "\n",
    "* In theory, we expect having a deeper network should only help but in reality, the deeper network has higher training error, and thus test error\n",
    "\n",
    "![](https://miro.medium.com/max/1400/1*4fv-3pCDh2ibQK33oDVFdA.png)\n",
    "\n",
    "\n",
    "* As we went deeper into a network the vanishing gradient problem becomes more and more significant and the solution to this problem was using a skip connection.\n",
    "\n",
    "![](https://d2l.ai/_images/resnet-block.svg)\n",
    "\n",
    "* In the figure above we can see how a skip connection works, the skip connection skips training from a few layers and then connects it to the output. This helps the network skip the layers, which are hurting the performance of the model. This allows us to go deeper into the network without facing the problem of vanishing gradient\n",
    "\n",
    "![](https://d2l.ai/_images/residual-block.svg)\n",
    "\n",
    "* The skip connections in ResNet solve the problem of vanishing gradient in deep neural networks by allowing this alternate shortcut path for the gradient to flow through.\n",
    "\n",
    "* **Key idea:** The other way that these connections help is by allowing the model to learn the identity functions which ensures that the higher layer will perform at least as good as the lower layer, and not worse.\n",
    "\n",
    "* Say we have a shallow network and a deep network that maps an input ‘x’ to output ’y’ by using the function H(x). We want the deep network to perform at least as good as the shallow network and not degrade the performance as we saw in case of plain neural networks. Plain networks are like VGG16, where adding more layers can hurt performance. Plain means, here, no skip connections.\n",
    "\n",
    "* One way of achieving so is if the additional layers in a deep network learn the identity function and thus their output equals inputs which do not allow them to degrade the performance even with extra layers.\n",
    "\n",
    "* In the case of skip connections, the input to the last activation is f(x) + x. So, in the worst case the network learns g(x) = 0, and then the input to the last activation is x which means the output will be the same as x itself.\n",
    "\n",
    "* So ResNets perform equally or better than the plain deep neural networks.\n",
    "\n",
    "* If the input x and the output of f(x) have the same depth, then nothing special needs to be done, mathematically, we can add f(x) + x with no errors.\n",
    "\n",
    "* If the input x and the output of f(x) have different then we need to use the 1x1 convolution so that when we follow the path on the right (the skip connection) that the depth of the two tensors f(x) and x match.\n",
    "\n",
    "* We can use strides in the first 3x3 convolutional block to reduce the width/height of the tensors, again the 1x1 convolution needs to use the same stride.\n",
    "\n",
    "* great video 7-minute to summarise it all up: https://www.youtube.com/watch?v=ZILIbUvp5lk "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gpvo-bqTmP7m"
   },
   "source": [
    "## Imports first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nvCXvXq5mP7p",
    "outputId": "27cc5a61-c2c9-43be-c6d4-e8df1bc97c50"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.2\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.datasets import fashion_mnist\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import np_utils\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Dropout, Flatten\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rqtYnFAUCAJN"
   },
   "source": [
    "## Same dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ttcGhwjKflgc"
   },
   "outputs": [],
   "source": [
    "class Residual(tf.keras.Model):\n",
    "    \"\"\"The Residual block of ResNet.\"\"\"\n",
    "    def __init__(self, num_channels, use_1x1conv=False, strides=1):\n",
    "        super().__init__()\n",
    "        self.conv1 = tf.keras.layers.Conv2D(num_channels, padding='same',\n",
    "                                            kernel_size=3, strides=strides)\n",
    "        self.conv2 = tf.keras.layers.Conv2D(num_channels, kernel_size=3,\n",
    "                                            padding='same')\n",
    "        self.conv3 = None\n",
    "        if use_1x1conv:\n",
    "            self.conv3 = tf.keras.layers.Conv2D(num_channels, kernel_size=1,\n",
    "                                                strides=strides)\n",
    "        self.bn1 = tf.keras.layers.BatchNormalization()\n",
    "        self.bn2 = tf.keras.layers.BatchNormalization()\n",
    "\n",
    "    def call(self, X):\n",
    "      \n",
    "        Y = tf.keras.activations.relu(self.bn1(self.conv1(X)))\n",
    "        Y = self.bn2(self.conv2(Y))\n",
    "        if self.conv3 is not None:\n",
    "            X = self.conv3(X)\n",
    "        Y += X # Y = Y + X\n",
    "        return tf.keras.activations.relu(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yLsdbOGXfli6"
   },
   "outputs": [],
   "source": [
    "# Input\n",
    "# Here, 4 batches of 6x6 with a depth of 3\n",
    "X = tf.random.normal((4, 6, 6, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OjV9GsrlfllS",
    "outputId": "e27e0f69-b18e-483b-cacf-7603c0766a70"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([4, 6, 6, 3])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Redidual layer with a depth of 3\n",
    "blk = Residual(3)\n",
    "\n",
    "# Check output\n",
    "Y = blk(X)\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KIHNwk0Rfybl"
   },
   "source": [
    "## Different dimensions and how to handle them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g4eYGq7dfloT",
    "outputId": "3b6cceae-8a31-44d0-c7a8-ca609bbcd057"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([4, 6, 6, 6])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Residual layer with a depth of 6. Now we need to use the 1x1 conv\n",
    "blk = Residual(6, use_1x1conv=True)\n",
    "blk(X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_Ecz7e4_flri",
    "outputId": "e684fbfa-9966-4f49-99dc-6cbf58f43b5f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([4, 3, 3, 6])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Residual layer with a depth of 6 and we want to half the width/height. Now we need to use the 1x1 conv\n",
    "blk = Residual(6, use_1x1conv=True, strides=2)\n",
    "blk(X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PsUcE69-fluJ",
    "outputId": "ad80d722-9c12-4b97-a8b5-d54619aabafc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([4, 3, 3, 3])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Residual layer with the same depth and we want to half the width/height. Now we need to use the 1x1 conv\n",
    "blk = Residual(3, use_1x1conv=True, strides=2)\n",
    "blk(X).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vMSMqnIagd_s"
   },
   "source": [
    "# The ResNet model. Stem:\n",
    "\n",
    "The first two layers of ResNet are the same as those of the GoogLeNet we described before: the 7*7 convolutional layer with 64 output channels and a stride of 2 is followed by the 3*3 max-pooling layer with a stride of 2. The difference is the batch normalization layer added after each convolutional layer in ResNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NU2ggsCWfl0r"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(tf.keras.layers.Conv2D(64, kernel_size=7, strides=2,padding='same', input_shape = (96,96,1)))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Activation('relu'))\n",
    "model.add(tf.keras.layers.MaxPool2D(pool_size=3, strides=2,padding='same'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3bhKOgkDfl3L",
    "outputId": "faff9c91-97fb-4716-e049-eaf84d4b5a21"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_11 (Conv2D)          (None, 48, 48, 64)        3200      \n",
      "                                                                 \n",
      " batch_normalization_8 (Batc  (None, 48, 48, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation (Activation)     (None, 48, 48, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 24, 24, 64)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,456\n",
      "Trainable params: 3,328\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "abst9RP-hJpr"
   },
   "source": [
    "# Module 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d6NRk7GOg3wz"
   },
   "outputs": [],
   "source": [
    "# Input is (24,24,64)\n",
    "model.add(Residual(64)) # Here we don't modify width,height,depth\n",
    "model.add(Residual(64)) # Here we don't modify width,height,depthˇ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1y8J_RiQg3zx",
    "outputId": "91329254-154c-47bc-ea4c-dbb61552fb7c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_11 (Conv2D)          (None, 48, 48, 64)        3200      \n",
      "                                                                 \n",
      " batch_normalization_8 (Batc  (None, 48, 48, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation (Activation)     (None, 48, 48, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 24, 24, 64)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " residual_4 (Residual)       (None, 24, 24, 64)        74368     \n",
      "                                                                 \n",
      " residual_5 (Residual)       (None, 24, 24, 64)        74368     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 152,192\n",
      "Trainable params: 151,552\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8aB_m8OQjkww"
   },
   "source": [
    "# Module 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r2ZrNFdNjkw5"
   },
   "outputs": [],
   "source": [
    "# Input is (24,24,64)\n",
    "model.add(Residual(128, use_1x1conv=True, strides=2)) # Here we modify width,height,depth\n",
    "model.add(Residual(128)) # Here we dont modify width,height,depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9Du7BY9Ujkw5",
    "outputId": "6f8d26bd-57aa-4a74-a8b8-311428608736"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_11 (Conv2D)          (None, 48, 48, 64)        3200      \n",
      "                                                                 \n",
      " batch_normalization_8 (Batc  (None, 48, 48, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation (Activation)     (None, 48, 48, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 24, 24, 64)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " residual_4 (Residual)       (None, 24, 24, 64)        74368     \n",
      "                                                                 \n",
      " residual_5 (Residual)       (None, 24, 24, 64)        74368     \n",
      "                                                                 \n",
      " residual_6 (Residual)       (None, 12, 12, 128)       230784    \n",
      "                                                                 \n",
      " residual_7 (Residual)       (None, 12, 12, 128)       296192    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 679,168\n",
      "Trainable params: 677,504\n",
      "Non-trainable params: 1,664\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qur7lL-2kSwo"
   },
   "source": [
    "# Module 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xDrtP_IUkSwp"
   },
   "outputs": [],
   "source": [
    "# Input is (12,12,128)\n",
    "model.add(Residual(256, use_1x1conv=True, strides=2)) # Here we modify width,height,depth\n",
    "model.add(Residual(256)) # Here we dont modify width,height,depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1aQsGo40kSwp",
    "outputId": "2c4f000a-498d-4460-847d-5e3ae5484347"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_11 (Conv2D)          (None, 48, 48, 64)        3200      \n",
      "                                                                 \n",
      " batch_normalization_8 (Batc  (None, 48, 48, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation (Activation)     (None, 48, 48, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 24, 24, 64)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " residual_4 (Residual)       (None, 24, 24, 64)        74368     \n",
      "                                                                 \n",
      " residual_5 (Residual)       (None, 24, 24, 64)        74368     \n",
      "                                                                 \n",
      " residual_6 (Residual)       (None, 12, 12, 128)       230784    \n",
      "                                                                 \n",
      " residual_7 (Residual)       (None, 12, 12, 128)       296192    \n",
      "                                                                 \n",
      " residual_8 (Residual)       (None, 6, 6, 256)         920320    \n",
      "                                                                 \n",
      " residual_9 (Residual)       (None, 6, 6, 256)         1182208   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,781,696\n",
      "Trainable params: 2,777,984\n",
      "Non-trainable params: 3,712\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rl4Y5W9NkY6Y"
   },
   "source": [
    "# Module 4\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k9EX35iYkY6Y"
   },
   "outputs": [],
   "source": [
    "# Input is (6,66,256)\n",
    "model.add(Residual(512, use_1x1conv=True, strides=2)) # Here we modify width,height,depth\n",
    "model.add(Residual(512)) # Here we dont modify width,height,depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Sdff4IaxkY6Y",
    "outputId": "6ca2a9c7-5229-4e2b-cd3f-f88e1406de29"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_11 (Conv2D)          (None, 48, 48, 64)        3200      \n",
      "                                                                 \n",
      " batch_normalization_8 (Batc  (None, 48, 48, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation (Activation)     (None, 48, 48, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 24, 24, 64)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " residual_4 (Residual)       (None, 24, 24, 64)        74368     \n",
      "                                                                 \n",
      " residual_5 (Residual)       (None, 24, 24, 64)        74368     \n",
      "                                                                 \n",
      " residual_6 (Residual)       (None, 12, 12, 128)       230784    \n",
      "                                                                 \n",
      " residual_7 (Residual)       (None, 12, 12, 128)       296192    \n",
      "                                                                 \n",
      " residual_8 (Residual)       (None, 6, 6, 256)         920320    \n",
      "                                                                 \n",
      " residual_9 (Residual)       (None, 6, 6, 256)         1182208   \n",
      "                                                                 \n",
      " residual_10 (Residual)      (None, 3, 3, 512)         3675648   \n",
      "                                                                 \n",
      " residual_11 (Residual)      (None, 3, 3, 512)         4723712   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,181,056\n",
      "Trainable params: 11,173,248\n",
      "Non-trainable params: 7,808\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D1dOkzHZlYSx"
   },
   "source": [
    "## Head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PXuvXpeNg39D"
   },
   "outputs": [],
   "source": [
    "model.add(tf.keras.layers.GlobalAvgPool2D())\n",
    "model.add(tf.keras.layers.Dense(units=10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-ObUu5m9g4BZ",
    "outputId": "4abea9ac-c328-4080-df34-41c5d2c120a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_11 (Conv2D)          (None, 48, 48, 64)        3200      \n",
      "                                                                 \n",
      " batch_normalization_8 (Batc  (None, 48, 48, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation (Activation)     (None, 48, 48, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 24, 24, 64)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " residual_4 (Residual)       (None, 24, 24, 64)        74368     \n",
      "                                                                 \n",
      " residual_5 (Residual)       (None, 24, 24, 64)        74368     \n",
      "                                                                 \n",
      " residual_6 (Residual)       (None, 12, 12, 128)       230784    \n",
      "                                                                 \n",
      " residual_7 (Residual)       (None, 12, 12, 128)       296192    \n",
      "                                                                 \n",
      " residual_8 (Residual)       (None, 6, 6, 256)         920320    \n",
      "                                                                 \n",
      " residual_9 (Residual)       (None, 6, 6, 256)         1182208   \n",
      "                                                                 \n",
      " residual_10 (Residual)      (None, 3, 3, 512)         3675648   \n",
      "                                                                 \n",
      " residual_11 (Residual)      (None, 3, 3, 512)         4723712   \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 512)              0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,186,186\n",
      "Trainable params: 11,178,378\n",
      "Non-trainable params: 7,808\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5uKHDElamaz5"
   },
   "source": [
    "![](https://d2l.ai/_images/resnet18.svg)\n",
    "\n",
    "\n",
    "18 convolutional layers in total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PvLNnz0vDnHc"
   },
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X1GTR35cmP7v"
   },
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uQ_KjFJomP7x",
    "outputId": "8f41cd85-2165-4903-bc12-44e9d3d3f678"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
      "29515/29515 [==============================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
      "26421880/26421880 [==============================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "5148/5148 [==============================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "4422102/4422102 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "(X_train, Y_train), (X_test, Y_test) = tf.keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E-Lw_bPQKQFX"
   },
   "source": [
    "## View the shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ueyWl-aUmP72",
    "outputId": "51b9e1e6-4979-49ff-fe7d-ef00bb588908"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape :  (60000, 28, 28) (60000,)\n"
     ]
    }
   ],
   "source": [
    "print('Training data shape : ', X_train.shape, Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3bsoluyzBOYR",
    "outputId": "8b01a8e8-0583-4a5e-ea6d-00faec3629a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing data shape :  (10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "print('Testing data shape : ', X_test.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z51sdOntmP78"
   },
   "source": [
    "## Find the unique numbers from the train labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o29O_gUTmP79",
    "outputId": "53ac2df6-2bb2-4756-9de2-319fe501015d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of outputs :  10\n",
      "Output classes :  [0 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "classes = np.unique(Y_train)\n",
    "nClasses = len(classes)\n",
    "print('Total number of outputs : ', nClasses)\n",
    "print('Output classes : ', classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GMMjLgbimP8B"
   },
   "source": [
    "## Plot some of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 335
    },
    "id": "qQpW4rajmP8C",
    "outputId": "7ca6dfc2-0d75-467b-c934-968e6231d54d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Ground Truth : 1')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_point = 15\n",
    "\n",
    "plt.figure(figsize=[10,5])\n",
    " \n",
    "# Display the first image in training data\n",
    "plt.subplot(121)\n",
    "plt.imshow(X_train[data_point,:,:], cmap='gray')\n",
    "plt.title(\"Ground Truth : {}\".format(Y_train[data_point]))\n",
    " \n",
    "# Display the first image in testing data\n",
    "plt.subplot(122)\n",
    "plt.imshow(X_test[data_point,:,:], cmap='gray')\n",
    "plt.title(\"Ground Truth : {}\".format(Y_test[data_point]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BA_mGK_NVHwn"
   },
   "source": [
    "## Reshape needed\n",
    "\n",
    "Keras wants to know the depth of an image. \n",
    "\n",
    "For CNNS, Keras wants the format of the data as follows: [batches, width, height, depth]. \n",
    "\n",
    "In this case the colour channel/depth of the images is 1. Currently the shape is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TBbn1qONB0M8",
    "outputId": "8aa3959f-9ac0-4190-e3ab-dedd4c4c8c00"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FmTJdq8LRDsx",
    "outputId": "6b03e564-a360-4693-b83d-382f0fcee3b7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a55ZpEbCB6kQ"
   },
   "source": [
    "But this doesn't have a depth value. So we can reshape it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D8HTp2YHVH4_"
   },
   "outputs": [],
   "source": [
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], X_train.shape[2], 1))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], X_test.shape[2], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pvHP86fjRU8z",
    "outputId": "d183c1b0-33d3-4c22-9e46-d7f7e66ff24a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9AMa4C0CRWb9",
    "outputId": "0d71822c-e8cd-4db8-9b88-80b25d7b4c48"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-lQP7CElWVfe"
   },
   "source": [
    "## View the shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5QKOvMPaWVfh",
    "outputId": "7e00285d-3372-43fd-9cfb-54bf22993886"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape :  (60000, 28, 28, 1) (60000,)\n"
     ]
    }
   ],
   "source": [
    "print('Training data shape : ', X_train.shape, Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zzGxSUONCRb2",
    "outputId": "1c5fb517-6e9c-4c18-88e4-42ff2e9d1456"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing data shape :  (10000, 28, 28, 1) (10000,)\n"
     ]
    }
   ],
   "source": [
    "print('Testing data shape : ', X_test.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UfClFp-6K7P6"
   },
   "source": [
    "## Convert from categorical labels to one-hot encoded vectors\n",
    "\n",
    "In this case there are 10 classes so we can tell the function to convert into a vector of length 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i3xjsPnVmP8j"
   },
   "outputs": [],
   "source": [
    "Y_train = np_utils.to_categorical(Y_train, 10)\n",
    "Y_test = np_utils.to_categorical(Y_test, 10)\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q7LVPnt1QPQM"
   },
   "source": [
    "## Small twist!\n",
    "\n",
    "API: https://www.tensorflow.org/api_docs/python/tf/data/Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PQNnZHhNSEKW"
   },
   "outputs": [],
   "source": [
    "train_ds = tf.data.Dataset.from_tensor_slices((X_train, Y_train))\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aHvmE76ySEMx"
   },
   "outputs": [],
   "source": [
    "def resize_images(image, label):\n",
    "    # Normalize images to have a mean of 0 and standard deviation of 1\n",
    "    image = tf.image.per_image_standardization(image)\n",
    "\n",
    "    image = tf.image.resize(image, (96,96))\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fqEzyUPLSOdv"
   },
   "outputs": [],
   "source": [
    "train_ds = (train_ds\n",
    "                  .map(resize_images)\n",
    "                  .shuffle(buffer_size=10000)\n",
    "                  .batch(batch_size=64, drop_remainder=True))\n",
    "test_ds = (test_ds\n",
    "                  .map(resize_images)\n",
    "                  .batch(batch_size=10, drop_remainder=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gozmsPxhmP8v"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "             optimizer='adam',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bUN6K31smP80"
   },
   "source": [
    "## Determine the number of trainable parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_DxDanOHmP80",
    "outputId": "72388a0b-078a-400a-e038-2543f47ac1a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_11 (Conv2D)          (None, 48, 48, 64)        3200      \n",
      "                                                                 \n",
      " batch_normalization_8 (Batc  (None, 48, 48, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation (Activation)     (None, 48, 48, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 24, 24, 64)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " residual_4 (Residual)       (None, 24, 24, 64)        74368     \n",
      "                                                                 \n",
      " residual_5 (Residual)       (None, 24, 24, 64)        74368     \n",
      "                                                                 \n",
      " residual_6 (Residual)       (None, 12, 12, 128)       230784    \n",
      "                                                                 \n",
      " residual_7 (Residual)       (None, 12, 12, 128)       296192    \n",
      "                                                                 \n",
      " residual_8 (Residual)       (None, 6, 6, 256)         920320    \n",
      "                                                                 \n",
      " residual_9 (Residual)       (None, 6, 6, 256)         1182208   \n",
      "                                                                 \n",
      " residual_10 (Residual)      (None, 3, 3, 512)         3675648   \n",
      "                                                                 \n",
      " residual_11 (Residual)      (None, 3, 3, 512)         4723712   \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 512)              0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,186,186\n",
      "Trainable params: 11,178,378\n",
      "Non-trainable params: 7,808\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ifPs0mftmP84"
   },
   "source": [
    "## Begin training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j8RZc1rhmP84",
    "outputId": "e30c7351-a29b-4fee-a649-7c0d3bfa1fb7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "937/937 [==============================] - 63s 60ms/step - loss: 0.3772 - accuracy: 0.8636\n",
      "Epoch 2/2\n",
      "937/937 [==============================] - 56s 59ms/step - loss: 0.2466 - accuracy: 0.9097\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff7221c7910>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_ds, epochs=2, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_j9LecHgmP8_"
   },
   "source": [
    "## Predict on all the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7TtfkDWjmP8_",
    "outputId": "11f3f067-def8-4f64-98f9-b2e04ea83aed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 7s 7ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b_zM7W80cFhJ",
    "outputId": "4c2a18a9-c6e9-4caf-ea3c-c9691c788320"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0abcDBFmcCz5"
   },
   "outputs": [],
   "source": [
    "correct_values = np.argmax(Y_test,axis=-1)\n",
    "predicted_classes = np.argmax(predictions,axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N7keRohxmP9H",
    "outputId": "65294904-8bb7-437d-9b58-564f9119e18c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89.7"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(predicted_classes,correct_values)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-1Ik7Odwj9L6"
   },
   "source": [
    "More efficient:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "agkf9IKkiotI"
   },
   "outputs": [],
   "source": [
    "targets = []\n",
    "for x,y in test_ds.as_numpy_iterator():\n",
    "  targets.extend(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5n-nlHvkjhkL",
    "outputId": "93f71306-88c2-496e-c3c1-3f816da2805e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.asarray(targets).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AnlUWwWmirtl",
    "outputId": "c94320e8-8ee1-4548-cc2f-3aeb7d493b2f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89.7"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(predicted_classes,np.argmax(targets,axis=-1))*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pci1FMrJcuSs"
   },
   "source": [
    "## Tasks:\n",
    "\n",
    "* Make adjustments to the actual residual block (width, choice and order of convolutions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6lPFztVMj3d6"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
